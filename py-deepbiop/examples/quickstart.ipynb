{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: DeepBioP for Deep Learning\n",
    "\n",
    "Welcome to DeepBioP! This notebook demonstrates the basics of loading and processing biological sequence data for deep learning.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Loading FASTQ files\n",
    "2. Filtering sequences by quality and length\n",
    "3. Encoding sequences for neural networks\n",
    "4. Using with PyTorch DataLoader\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from deepbiop import fq\n",
    "from deepbiop.transforms import FilterCompose, TransformDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading FASTQ Data\n",
    "\n",
    "The simplest way to load FASTQ data is with `FastqStreamDataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "test_file = Path(\"../tests/data/test.fastq\")\n",
    "\n",
    "if test_file.exists():\n",
    "    dataset = fq.FastqStreamDataset(str(test_file))\n",
    "\n",
    "    # Look at first record\n",
    "    record = next(iter(dataset))\n",
    "\n",
    "    print(f\"Record ID: {record['id']}\")\n",
    "    print(f\"Sequence length: {len(record['sequence'])} bases\")\n",
    "    print(f\"First 20 bases: {record['sequence'][:20]}\")\n",
    "    print(f\"Quality scores: {record['quality'][:20]}\")\n",
    "else:\n",
    "    print(f\"Test file not found at {test_file}\")\n",
    "    print(\"This is just a demo - in practice, use your own FASTQ files!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filtering Sequences\n",
    "\n",
    "Let's filter sequences by quality and length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filters\n",
    "quality_filter = fq.QualityFilter(min_mean_quality=25.0)\n",
    "length_filter = fq.LengthFilter(min_length=50, max_length=500)\n",
    "\n",
    "# Combine filters\n",
    "filters = FilterCompose([quality_filter, length_filter])\n",
    "\n",
    "# Apply filters\n",
    "if test_file.exists():\n",
    "    passed = 0\n",
    "    filtered = 0\n",
    "\n",
    "    for record in dataset:\n",
    "        if filters.filter(record):\n",
    "            passed += 1\n",
    "        else:\n",
    "            filtered += 1\n",
    "\n",
    "        if passed + filtered >= 100:  # Check first 100\n",
    "            break\n",
    "\n",
    "    print(f\"Passed filters: {passed}\")\n",
    "    print(f\"Filtered out: {filtered}\")\n",
    "    print(f\"Pass rate: {100 * passed / (passed + filtered):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encoding Sequences\n",
    "\n",
    "Neural networks need numerical data. Let's one-hot encode DNA sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot encoder\n",
    "encoder = fq.OneHotEncoder(encoding_type=\"dna\", unknown_strategy=\"skip\")\n",
    "\n",
    "# Encode a sample sequence\n",
    "sample = {\"sequence\": b\"ACGT\", \"quality\": None}\n",
    "\n",
    "encoded = encoder(sample)\n",
    "\n",
    "print(\"One-hot encoded sequence:\")\n",
    "print(encoded[\"sequence\"])\n",
    "print(f\"\\nShape: {encoded['sequence'].shape}\")\n",
    "print(\"Each row is [A, C, G, T]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Complete Pipeline\n",
    "\n",
    "Now let's combine filtering and encoding in one pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_file.exists():\n",
    "    # Create base dataset\n",
    "    dataset = fq.FastqStreamDataset(str(test_file))\n",
    "\n",
    "    # Create transform pipeline (for encoding)\n",
    "    transform = fq.OneHotEncoder(encoding_type=\"dna\", unknown_strategy=\"skip\")\n",
    "\n",
    "    # Create filter pipeline\n",
    "    filter_pipeline = FilterCompose(\n",
    "        [fq.QualityFilter(min_mean_quality=25.0), fq.LengthFilter(min_length=50)]\n",
    "    )\n",
    "\n",
    "    # Wrap with TransformDataset\n",
    "    processed = TransformDataset(\n",
    "        dataset, transform=transform, filter_fn=filter_pipeline\n",
    "    )\n",
    "\n",
    "    # Process records\n",
    "    for i, record in enumerate(processed):\n",
    "        if i == 0:\n",
    "            print(\"First processed record:\")\n",
    "            print(f\"  ID: {record['id']}\")\n",
    "            print(f\"  Encoded shape: {record['sequence'].shape}\")\n",
    "            print(\"  First 5 bases (one-hot):\")\n",
    "            print(record[\"sequence\"][:5])\n",
    "\n",
    "        if i >= 4:  # Process first 5\n",
    "            break\n",
    "\n",
    "    print(f\"\\nProcessed {i + 1} records successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using with PyTorch DataLoader\n",
    "\n",
    "For training neural networks, wrap the dataset in a PyTorch DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        \"\"\"Custom collate function with padding.\"\"\"\n",
    "        sequences = [torch.from_numpy(item[\"sequence\"]).float() for item in batch]\n",
    "\n",
    "        # Pad to max length\n",
    "        max_len = max(seq.shape[0] for seq in sequences)\n",
    "        padded = torch.zeros(len(sequences), max_len, 4)  # 4 for A,C,G,T\n",
    "\n",
    "        for i, seq in enumerate(sequences):\n",
    "            padded[i, : seq.shape[0]] = seq\n",
    "\n",
    "        return {\n",
    "            \"sequences\": padded,\n",
    "            \"lengths\": torch.tensor([seq.shape[0] for seq in sequences]),\n",
    "        }\n",
    "\n",
    "    if test_file.exists():\n",
    "        # Create DataLoader\n",
    "        loader = DataLoader(\n",
    "            processed, batch_size=4, collate_fn=collate_fn, num_workers=0\n",
    "        )\n",
    "\n",
    "        # Get one batch\n",
    "        batch = next(iter(loader))\n",
    "\n",
    "        print(\"DataLoader batch:\")\n",
    "        print(f\"  Batch shape: {batch['sequences'].shape}\")\n",
    "        print(f\"  Sequence lengths: {batch['lengths']}\")\n",
    "        print(\"\\nReady for training!\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed. Install with: pip install torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned how to:\n",
    "\n",
    "- âœ… Load FASTQ files with `FastqStreamDataset`\n",
    "- âœ… Filter sequences by quality and length\n",
    "- âœ… Encode sequences as one-hot arrays\n",
    "- âœ… Combine filters and transforms in a pipeline\n",
    "- âœ… Use with PyTorch DataLoader for training\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Check out these notebooks for more advanced usage:\n",
    "\n",
    "- **[PyTorch Training](pytorch_training.ipynb)**: Complete PyTorch integration examples\n",
    "- **[Lightning Module](lightning_module.ipynb)**: PyTorch Lightning workflows  \n",
    "- **[Transformers DNA](transformers_dna.ipynb)**: Hugging Face Transformers integration\n",
    "\n",
    "Happy coding! ðŸ§¬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
